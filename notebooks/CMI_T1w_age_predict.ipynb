{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLVyU7QTV8z8"
   },
   "source": [
    "---\n",
    "## Step 0: Load & Setup The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TqLSFI6dV8z-",
    "outputId": "cdbbf1b0-147f-44b2-a26a-e64d391481ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general python packages\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as ran\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning packages\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv3D, MaxPooling3D, AveragePooling3D, Input, ZeroPadding3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop, Adamax, Nadam, SGD # using Adam in this model, but just showing the other options here for future reference\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ04WLFfKrSu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqStSb7GJQM-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slab/environments/OHBM_DL/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# neuroimaging-specific python packages\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "590v94VWMvMC",
    "outputId": "bc3f3660-bcec-4af1-f018-09e2f30c7883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/parasite/CMI/OHBM_DL_data\n"
     ]
    }
   ],
   "source": [
    "cd /net/parasite/CMI/OHBM_DL_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('/net/parasite/CMI/OHBM_DL_data/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('/net/parasite/CMI/OHBM_DL_data/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('/net/parasite/CMI/OHBM_DL_data/train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('/net/parasite/CMI/OHBM_DL_data/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG4sgLJfV80r"
   },
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "image_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxu1qZ1MV80u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 724\n",
      "Number of test examples 182\n",
      "Image data shape = (121, 145, 121, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples =\", n_train)\n",
    "print (\"Number of test examples\", n_test)\n",
    "print(\"Image data shape =\", image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4gGW_ksV80_"
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_CMI_T1w_age_6-1-19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COQla7JGWYps"
   },
   "source": [
    "# Step 1: Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9hiCC2oV81k",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slab/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 121, 145, 121, 64) 5248      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 121, 145, 121, 64) 110656    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 121, 145, 121, 64) 110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 60, 72, 60, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 72, 60, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 60, 72, 60, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 60, 72, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 30, 36, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 36, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 30, 36, 30, 16)    13840     \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 30, 36, 30, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 15, 18, 15, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 18, 15, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 15, 18, 15, 8)     3464      \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 18, 15, 8)     1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 7, 9, 7, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 9, 7, 8)        32        \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 3, 4, 3, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 1024)              295936    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 632,977\n",
      "Trainable params: 632,737\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # The simplest model, a linear stack of layers\n",
    "\n",
    "model.add(Conv3D(filters=64,\n",
    "                 kernel_size=(3,3,3), #determines the width, height, depth of the 3D convolution window\n",
    "                 activation='elu', #Exponential Linear Unit\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform', \n",
    "                 input_shape=image_shape)) # only the first layer needs to be told this info\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2))) # pooling is also referred to as a downsampling layer\n",
    "model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch (aka make the mean activation close to 0 and the activation standard deviation close to 1)\n",
    "\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(AveragePooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu',name='features')) #convert the output of the convolutional part of the CNN into a 1D feature vector. Length of vector = n_classes\n",
    "model.add(Dense(1)) # final output is a single number (Age in this model)\n",
    "model.summary()\n",
    "\n",
    "filename=\"best_weights.h5\"\n",
    "filename2=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVOUv2emV81q"
   },
   "outputs": [],
   "source": [
    "checkpoints = []\n",
    "\n",
    "if not os.path.exists('Results00/'):\n",
    "    os.makedirs('Results00/')\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=1))\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename2, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=False, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=20))\n",
    "\n",
    "checkpoints.append(TensorBoard(log_dir='Results00/TensorBoardLogs', \n",
    "                               histogram_freq=0, \n",
    "                               write_graph=True, \n",
    "                               write_images=False, \n",
    "                               embeddings_freq=0, \n",
    "                               embeddings_layer_names=['features'], \n",
    "                               embeddings_metadata='metadata.tsv'))\n",
    "\n",
    "checkpoints.append(EarlyStopping(monitor='val_loss', mode='min', min_delta=0, patience=10))\n",
    "checkpoints.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0))\n",
    "checkpoints.append(CSVLogger('Results00/log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t1hNJ5FV81t"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', # the objective that the model will try to minimize\n",
    "              optimizer='adam', \n",
    "              metrics=['mae', 'acc']) # add in any other metrics you want to use to show performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAaugGfNqGbp"
   },
   "source": [
    "**Saving/loading whole models (architecture + weights + optimizer state):**\n",
    "1. the architecture of the model, allowing to re-create the model\n",
    "2. the weights of the model\n",
    "3. the training configuration (loss, optimizer)\n",
    "4. the state of the optimizer, allowing to resume training exactly where you left off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLQOan47WnC2"
   },
   "source": [
    "# Step 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0OjFqxgV81y",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 651 samples, validate on 73 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6,64,121,145,121] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling3d_1/MaxPool3D_grad/MaxPool3DGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-71f006ee8a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=checkpoints)\n\u001b[0m",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6,64,121,145,121] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling3d_1/MaxPool3D_grad/MaxPool3DGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10 # defines for how many times the training will repeat. 1 epoch is 1 forward pass and 1 backward pass over all the training examples\n",
    "BATCH_SIZE=6 # the number of training examples in one forward/backward pass (or for 1 epoch)\n",
    "history1= model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          batch_size= BATCH_SIZE, \n",
    "          epochs = NUM_EPOCHS,\n",
    "          callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pWsjo8fV812"
   },
   "outputs": [],
   "source": [
    "log_dir ='Results00/'\n",
    "from os.path import exists, join\n",
    "with open(join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bJ8tQWMpx_8"
   },
   "source": [
    "# Step 3: Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r6PIHp4p1j_"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=x_test, y=y_test, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeszU1NTp1-c"
   },
   "source": [
    "# Step 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qFMHFfep4xo"
   },
   "outputs": [],
   "source": [
    "model.predict_on_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhwIVrcMs5p4"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CMI_T1w_age_predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
