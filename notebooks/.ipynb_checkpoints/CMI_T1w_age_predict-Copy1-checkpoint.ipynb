{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLVyU7QTV8z8"
   },
   "source": [
    "---\n",
    "## Step 0: Load & Setup The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TqLSFI6dV8z-",
    "outputId": "cdbbf1b0-147f-44b2-a26a-e64d391481ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general python packages\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as ran\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning packages\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv3D, MaxPooling3D, AveragePooling3D, Input, ZeroPadding3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop, Adamax, Nadam, SGD # using Adam in this model, but just showing the other options here for future reference\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ04WLFfKrSu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqStSb7GJQM-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slab/environments/OHBM_DL/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# neuroimaging-specific python packages\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:1'):  # 0 is titan\n",
    "   a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "   b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "   c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/slab/environments/OHBM_DL/bin:/home/slab/environments/OHBM_DL/bin:/usr/local/cuda-10.0/bin:/usr/local/cuda-10.0/NsightCompute-1.0:/net/pizza/SST/google-cloud-sdk/bin:/usr/local/freesurfer/freesurfer_5.3.0_centos6_HCP/bin:/usr/local/freesurfer/freesurfer_5.3.0_centos6_HCP/fsfast/bin:/usr/local/freesurfer/freesurfer_5.3.0_centos6_HCP/tktools:/usr/local/fsl_5.0.10/bin:/usr/local/freesurfer/freesurfer_5.3.0_centos6_HCP/mni/bin:/usr/local/fsl_5.0.10/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/afni/afni-common'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "uqCGr55A-XWT",
    "outputId": "874fcf0d-280c-4e40-bdb5-7fb0a3eb14da"
   },
   "outputs": [],
   "source": [
    "# Connect to Google Drive where data is stored\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "root_path = 'gdrive/My Drive/OHBM_DL_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1ONeN50yrMR"
   },
   "outputs": [],
   "source": [
    "# Read in csv file with subject info\n",
    "pheno = pd.read_csv('/net/parasite/CMI/OHBM_DL_data/pheno_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "KoATQCS98sGJ",
    "outputId": "0e69f486-0aaf-4a53-f76d-9ec11173ee5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    906.000000\n",
       "mean      10.824074\n",
       "std        3.558937\n",
       "min        5.036048\n",
       "25%        8.039898\n",
       "50%       10.031599\n",
       "75%       13.057266\n",
       "max       21.816563\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "E7s_ypgF-ONi",
    "outputId": "12fe716b-3019-49c8-9c53-a360b1af055a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4,6))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(pheno['Age'],bins=15)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(pheno['Sex'],bins=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-fJfgAAzDh5"
   },
   "outputs": [],
   "source": [
    "# Create numpy array of age labels for all subjects\n",
    "age_all = pheno['Age'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "590v94VWMvMC",
    "outputId": "bc3f3660-bcec-4af1-f018-09e2f30c7883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/parasite/CMI/OHBM_DL_data\n"
     ]
    }
   ],
   "source": [
    "cd /net/parasite/CMI/OHBM_DL_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertGMNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_GMprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertWMNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_WMprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertCSFNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_CSFprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already run, don't re-run\n",
    "SubjectDataFrame = pheno\n",
    "ConvertNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/', outFile='/net/parasite/CMI/OHBM_DL_data/GMnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already run, don't re-run\n",
    "SubjectDataFrame = pheno\n",
    "ConvertWMNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/', outFile='/net/parasite/CMI/OHBM_DL_data/WMnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectDataFrame = pheno\n",
    "ConvertCSFNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/', outFile='/net/parasite/CMI/OHBM_DL_data/CSFnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tissue_masks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMfiles = glob.glob('tissue_masks/*GMprobmask.nii')\n",
    "WMfiles = glob.glob('tissue_masks/*WMprobmask.nii')\n",
    "CSFfiles = glob.glob('tissue_masks/*CSFprobmask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GMfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WMfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CSFfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMimages = []\n",
    "WMimages = []\n",
    "CSFimages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nib.load('tissue_masks/sub-NDARME930DE7_GMprobmask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 145, 121)\n"
     ]
    }
   ],
   "source": [
    "for f in range(len(GMfiles)):\n",
    "    a = nib.load(GMfiles[f])\n",
    "    a = a.get_data()\n",
    "    for i in range(a.shape[1]):\n",
    "        GMimages.append((a[:,i,:]))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMimages = np.asarray(GMimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131370, 121, 121)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMimages = GMimages.reshape(-1, 121, 121, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131370, 121, 121, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWAnxGKYV80Y"
   },
   "outputs": [],
   "source": [
    "#load .nii, view dim, view images, crop\n",
    "image = nilearn.image.load_img('tissue_masks/sub-NDARME930DE7_GMprobmask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFi1Liml5LhR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_anat(image, draw_cross=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n26pDG4e4WVw"
   },
   "outputs": [],
   "source": [
    "crop_image = nilearn.image.crop_img(image, rtol=1e-08, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFi1Liml5LhR"
   },
   "outputs": [],
   "source": [
    "plotting.plot_anat(crop_image, draw_cross=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_input_dir = 'GMnumpyArrays/'\n",
    "input_names = [name for name in os.listdir(GM_input_dir)]\n",
    "WM_input_dir = 'WMnumpyArrays/'\n",
    "CSF_input_dir = 'CSFnumpyArrays/'\n",
    "all_subs = []\n",
    "for idx, name in enumerate(input_names):\n",
    "    GM_name = GM_input_dir + name\n",
    "    sub_GM = np.load(GM_name)\n",
    "    WM_name = WM_input_dir + name\n",
    "    sub_WM = np.load(WM_name)\n",
    "    CSF_name = CSF_input_dir + name\n",
    "    sub_CSF = np.load(CSF_name)\n",
    "    sub_stacked = np.stack((sub_GM, sub_WM, sub_CSF), axis=3)\n",
    "    all_subs.append(sub_stacked)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs_array = np.asarray(all_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input shape\n",
    "### all_subs_array.shape[0] = batch size (number of subjects)\n",
    "### all_subs_array.shape[1] = rows (x)\n",
    "### all_subs_array.shape[2] = columns (y)\n",
    "### all_subs_array.shape[3] = depth (z)\n",
    "### all_subs_array.shape[4] = channels (number of segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906, 121, 145, 121, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subs_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check shape of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvxYyx6jV80l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_subs_array, age_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG4sgLJfV80r"
   },
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "image_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxu1qZ1MV80u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 724\n",
      "Number of test examples 182\n",
      "Image data shape = (121, 145, 121, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples =\", n_train)\n",
    "print (\"Number of test examples\", n_test)\n",
    "print(\"Image data shape =\", image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efM40Jx-V80z"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GgDAAfIV807"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train.npy', X_train, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test.npy', X_test, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_labels.npy', y_train, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_labels.npy', y_test, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('/net/parasite/CMI/OHBM_DL_data/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('/net/parasite/CMI/OHBM_DL_data/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('/net/parasite/CMI/OHBM_DL_data/train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('/net/parasite/CMI/OHBM_DL_data/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4gGW_ksV80_"
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_CMI_T1w_age_6-1-19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COQla7JGWYps"
   },
   "source": [
    "# Step 1: Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf.device('/gpu:1'):\n",
    "    config = tf.ConfigProto( device_count = {'GPU': 1} )\n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9hiCC2oV81k",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slab/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 121, 145, 121, 64) 5248      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 121, 145, 121, 64) 110656    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 121, 145, 121, 64) 110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 60, 72, 60, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 72, 60, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 60, 72, 60, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 60, 72, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 30, 36, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 36, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 30, 36, 30, 16)    13840     \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 30, 36, 30, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 15, 18, 15, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 18, 15, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 15, 18, 15, 8)     3464      \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 18, 15, 8)     1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 7, 9, 7, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 9, 7, 8)        32        \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 3, 4, 3, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 1024)              295936    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 632,977\n",
      "Trainable params: 632,737\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # The simplest model, a linear stack of layers\n",
    "\n",
    "model.add(Conv3D(filters=64,\n",
    "                 kernel_size=(3,3,3), #determines the width, height, depth of the 3D convolution window\n",
    "                 activation='elu', #Exponential Linear Unit\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform', \n",
    "                 input_shape=image_shape)) # only the first layer needs to be told this info\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2))) # pooling is also referred to as a downsampling layer\n",
    "model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch (aka make the mean activation close to 0 and the activation standard deviation close to 1)\n",
    "\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(AveragePooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu',name='features')) #convert the output of the convolutional part of the CNN into a 1D feature vector. Length of vector = n_classes\n",
    "model.add(Dense(1)) # final output is a single number (Age in this model)\n",
    "model.summary()\n",
    "\n",
    "filename=\"best_weights.h5\"\n",
    "filename2=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVOUv2emV81q"
   },
   "outputs": [],
   "source": [
    "checkpoints = []\n",
    "\n",
    "if not os.path.exists('Results00/'):\n",
    "    os.makedirs('Results00/')\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=1))\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename2, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=False, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=20))\n",
    "\n",
    "checkpoints.append(TensorBoard(log_dir='Results00/TensorBoardLogs', \n",
    "                               histogram_freq=0, \n",
    "                               write_graph=True, \n",
    "                               write_images=False, \n",
    "                               embeddings_freq=0, \n",
    "                               embeddings_layer_names=['features'], \n",
    "                               embeddings_metadata='metadata.tsv'))\n",
    "\n",
    "checkpoints.append(EarlyStopping(monitor='val_loss', mode='min', min_delta=0, patience=10))\n",
    "checkpoints.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0))\n",
    "checkpoints.append(CSVLogger('Results00/log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t1hNJ5FV81t"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', # the objective that the model will try to minimize\n",
    "              optimizer='adam', \n",
    "              metrics=['mae', 'acc']) # add in any other metrics you want to use to show performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAaugGfNqGbp"
   },
   "source": [
    "**Saving/loading whole models (architecture + weights + optimizer state):**\n",
    "1. the architecture of the model, allowing to re-create the model\n",
    "2. the weights of the model\n",
    "3. the training configuration (loss, optimizer)\n",
    "4. the state of the optimizer, allowing to resume training exactly where you left off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLQOan47WnC2"
   },
   "source": [
    "# Step 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0OjFqxgV81y",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slab/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 651 samples, validate on 73 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10 # defines for how many times the training will repeat. 1 epoch is 1 forward pass and 1 backward pass over all the training examples\n",
    "BATCH_SIZE=10 # the number of training examples in one forward/backward pass (or for 1 epoch)\n",
    "history1= model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          batch_size= BATCH_SIZE, \n",
    "          epochs = NUM_EPOCHS,\n",
    "          callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pWsjo8fV812"
   },
   "outputs": [],
   "source": [
    "log_dir ='Results00/'\n",
    "from os.path import exists, join\n",
    "with open(join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bJ8tQWMpx_8"
   },
   "source": [
    "# Step 3: Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r6PIHp4p1j_"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=x_test, y=y_test, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeszU1NTp1-c"
   },
   "source": [
    "# Step 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qFMHFfep4xo"
   },
   "outputs": [],
   "source": [
    "model.predict_on_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhwIVrcMs5p4"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CMI_T1w_age_predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
