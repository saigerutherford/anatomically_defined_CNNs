{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLVyU7QTV8z8"
   },
   "source": [
    "---\n",
    "## Step 0: Load & Setup The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TqLSFI6dV8z-",
    "outputId": "cdbbf1b0-147f-44b2-a26a-e64d391481ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general python packages\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as ran\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning packages\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv3D, MaxPooling3D, AveragePooling3D, Input, ZeroPadding3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop, Adamax, Nadam, SGD # using Adam in this model, but just showing the other options here for future reference\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ04WLFfKrSu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqStSb7GJQM-"
   },
   "outputs": [],
   "source": [
    "# neuroimaging-specific python packages\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "uqCGr55A-XWT",
    "outputId": "874fcf0d-280c-4e40-bdb5-7fb0a3eb14da"
   },
   "outputs": [],
   "source": [
    "# Connect to Google Drive where data is stored\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "root_path = 'gdrive/My Drive/OHBM_DL_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1ONeN50yrMR"
   },
   "outputs": [],
   "source": [
    "# Read in csv file with subject info\n",
    "pheno = pd.read_csv('/net/parasite/CMI/OHBM_DL_data/pheno_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "KoATQCS98sGJ",
    "outputId": "0e69f486-0aaf-4a53-f76d-9ec11173ee5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    906.000000\n",
       "mean      10.824074\n",
       "std        3.558937\n",
       "min        5.036048\n",
       "25%        8.039898\n",
       "50%       10.031599\n",
       "75%       13.057266\n",
       "max       21.816563\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "E7s_ypgF-ONi",
    "outputId": "12fe716b-3019-49c8-9c53-a360b1af055a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.hist(pheno['Age'],bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-fJfgAAzDh5"
   },
   "outputs": [],
   "source": [
    "# Create numpy array of age labels for all subjects\n",
    "age_all = pheno['Age'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "590v94VWMvMC",
    "outputId": "bc3f3660-bcec-4af1-f018-09e2f30c7883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/parasite/CMI/OHBM_DL_data\n"
     ]
    }
   ],
   "source": [
    "cd /net/parasite/CMI/OHBM_DL_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertGMNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_GMprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertWMNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_WMprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertCSFNIItoNPY(inFile, outFile, SubjectDataFrame):\n",
    "    for _, row in SubjectDataFrame.iterrows():\n",
    "        subject = row['Subject']\n",
    "        #print('Saving Subject {}'.format(subject))\n",
    "        fileName = '{}{}_CSFprobmask.nii'.format(inFile, str(subject))\n",
    "        NIIimage = nib.load(fileName)\n",
    "        imageArray = NIIimage.get_data()\n",
    "        outFileName = outFile + str(subject)\n",
    "        np.save(outFileName, imageArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectDataFrame = pheno\n",
    "ConvertGMNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/resampled/', outFile='/net/parasite/CMI/OHBM_DL_data/rs_GMnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectDataFrame = pheno\n",
    "ConvertWMNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/resampled/', outFile='/net/parasite/CMI/OHBM_DL_data/rs_WMnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectDataFrame = pheno\n",
    "ConvertCSFNIItoNPY(inFile='/net/parasite/CMI/OHBM_DL_data/tissue_masks/resampled/', outFile='/net/parasite/CMI/OHBM_DL_data/rs_CSFnumpyArrays/', SubjectDataFrame=SubjectDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_input_dir = 'rs_GMnumpyArrays/'\n",
    "input_names = [name for name in os.listdir(GM_input_dir)]\n",
    "WM_input_dir = 'rs_WMnumpyArrays/'\n",
    "CSF_input_dir = 'rs_CSFnumpyArrays/'\n",
    "all_subs = []\n",
    "for idx, name in enumerate(input_names):\n",
    "    GM_name = GM_input_dir + name\n",
    "    sub_GM = np.load(GM_name)\n",
    "    WM_name = WM_input_dir + name\n",
    "    sub_WM = np.load(WM_name)\n",
    "    CSF_name = CSF_input_dir + name\n",
    "    sub_CSF = np.load(CSF_name)\n",
    "    sub_stacked = np.stack((sub_GM, sub_WM, sub_CSF), axis=3)\n",
    "    all_subs.append(sub_stacked)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs_array = np.asarray(all_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input shape\n",
    "### all_subs_array.shape[0] = batch size (number of subjects)\n",
    "### all_subs_array.shape[1] = rows (x)\n",
    "### all_subs_array.shape[2] = columns (y)\n",
    "### all_subs_array.shape[3] = depth (z)\n",
    "### all_subs_array.shape[4] = channels (number of segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906, 48, 60, 46, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subs_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check shape of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvxYyx6jV80l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_subs_array, age_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG4sgLJfV80r"
   },
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "image_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxu1qZ1MV80u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 724\n",
      "Number of test examples 182\n",
      "Image data shape = (48, 60, 46, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples =\", n_train)\n",
    "print (\"Number of test examples\", n_test)\n",
    "print(\"Image data shape =\", image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efM40Jx-V80z"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GgDAAfIV807"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4gGW_ksV80_"
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_CMI_T1w_age_6-1-19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COQla7JGWYps"
   },
   "source": [
    "# Step 1: Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf.device('/gpu:1'):\n",
    "    config = tf.ConfigProto( device_count = {'GPU': 1} )\n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9hiCC2oV81k",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slab/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 48, 60, 46, 64)    5248      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 48, 60, 46, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 48, 60, 46, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 24, 30, 23, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 30, 23, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 24, 30, 23, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 24, 30, 23, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 15, 11, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 15, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 12, 15, 11, 16)    13840     \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 12, 15, 11, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 7, 5, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 7, 5, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 6, 7, 5, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 6, 7, 5, 8)        1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 3, 2, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 2, 8)        32        \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 1, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 1024)              9216      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 346,257\n",
      "Trainable params: 346,017\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # The simplest model, a linear stack of layers\n",
    "\n",
    "model.add(Conv3D(filters=64,\n",
    "                 kernel_size=(3,3,3), #determines the width, height, depth of the 3D convolution window\n",
    "                 activation='elu', #Exponential Linear Unit\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform', \n",
    "                 input_shape=image_shape)) # only the first layer needs to be told this info\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=64, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2))) # pooling is also referred to as a downsampling layer\n",
    "model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch (aka make the mean activation close to 0 and the activation standard deviation close to 1)\n",
    "\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=16, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(Conv3D(filters=8, kernel_size=(3,3,3), activation='elu', strides=(1,1,1), padding='same'))\n",
    "model.add(MaxPooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(AveragePooling3D((2,2,2),strides=(2,2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu',name='features')) #convert the output of the convolutional part of the CNN into a 1D feature vector. Length of vector = n_classes\n",
    "model.add(Dense(1)) # final output is a single number (Age in this model)\n",
    "model.summary()\n",
    "\n",
    "filename=\"best_weights.h5\"\n",
    "filename2=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVOUv2emV81q"
   },
   "outputs": [],
   "source": [
    "checkpoints = []\n",
    "\n",
    "if not os.path.exists('Results00/'):\n",
    "    os.makedirs('Results00/')\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=1))\n",
    "\n",
    "checkpoints.append(ModelCheckpoint('Results00/'+filename2, \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=False, \n",
    "                                   save_weights_only=True, \n",
    "                                   mode='auto', \n",
    "                                   period=20))\n",
    "\n",
    "checkpoints.append(TensorBoard(log_dir='Results00/TensorBoardLogs', \n",
    "                               histogram_freq=0, \n",
    "                               write_graph=True, \n",
    "                               write_images=False, \n",
    "                               embeddings_freq=0, \n",
    "                               embeddings_layer_names=['features'], \n",
    "                               embeddings_metadata='metadata.tsv'))\n",
    "\n",
    "checkpoints.append(EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=10))\n",
    "checkpoints.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0))\n",
    "checkpoints.append(CSVLogger('Results00/log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t1hNJ5FV81t"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', # the objective that the model will try to minimize\n",
    "              optimizer='adam', \n",
    "              metrics=['mae', 'acc']) # add in any other metrics you want to use to show performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAaugGfNqGbp"
   },
   "source": [
    "**Saving/loading whole models (architecture + weights + optimizer state):**\n",
    "1. the architecture of the model, allowing to re-create the model\n",
    "2. the weights of the model\n",
    "3. the training configuration (loss, optimizer)\n",
    "4. the state of the optimizer, allowing to resume training exactly where you left off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLQOan47WnC2"
   },
   "source": [
    "# Step 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0OjFqxgV81y",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slab/environments/OHBM_DL/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 651 samples, validate on 73 samples\n",
      "Epoch 1/30\n",
      "651/651 [==============================] - 31s 48ms/step - loss: 63.5485 - mean_absolute_error: 6.6958 - acc: 0.0000e+00 - val_loss: 100.6489 - val_mean_absolute_error: 9.3710 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 100.64893, saving model to Results00/best_weights.h5\n",
      "Epoch 2/30\n",
      "651/651 [==============================] - 23s 36ms/step - loss: 12.9869 - mean_absolute_error: 2.9688 - acc: 0.0000e+00 - val_loss: 77.4324 - val_mean_absolute_error: 8.0488 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 100.64893 to 77.43236, saving model to Results00/best_weights.h5\n",
      "Epoch 3/30\n",
      "651/651 [==============================] - 23s 36ms/step - loss: 12.8644 - mean_absolute_error: 2.9840 - acc: 0.0000e+00 - val_loss: 20.9036 - val_mean_absolute_error: 3.9944 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 77.43236 to 20.90364, saving model to Results00/best_weights.h5\n",
      "Epoch 4/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.8370 - mean_absolute_error: 2.9268 - acc: 0.0000e+00 - val_loss: 72.5321 - val_mean_absolute_error: 7.7209 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 20.90364\n",
      "Epoch 5/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.7471 - mean_absolute_error: 2.9328 - acc: 0.0000e+00 - val_loss: 33.6599 - val_mean_absolute_error: 4.9947 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 20.90364\n",
      "Epoch 6/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.7132 - mean_absolute_error: 2.9080 - acc: 0.0000e+00 - val_loss: 13.1625 - val_mean_absolute_error: 3.1131 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 20.90364 to 13.16253, saving model to Results00/best_weights.h5\n",
      "Epoch 7/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.5171 - mean_absolute_error: 2.9034 - acc: 0.0000e+00 - val_loss: 13.1228 - val_mean_absolute_error: 3.0814 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 13.16253 to 13.12279, saving model to Results00/best_weights.h5\n",
      "Epoch 8/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.7350 - mean_absolute_error: 2.9322 - acc: 0.0000e+00 - val_loss: 107.5972 - val_mean_absolute_error: 9.7161 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 13.12279\n",
      "Epoch 9/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.6614 - mean_absolute_error: 2.9101 - acc: 0.0000e+00 - val_loss: 58.9197 - val_mean_absolute_error: 6.7758 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 13.12279\n",
      "Epoch 10/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.4505 - mean_absolute_error: 2.8871 - acc: 0.0000e+00 - val_loss: 17.1642 - val_mean_absolute_error: 3.6922 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 13.12279\n",
      "Epoch 11/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.6547 - mean_absolute_error: 2.9071 - acc: 0.0000e+00 - val_loss: 20.1043 - val_mean_absolute_error: 3.9534 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 13.12279\n",
      "Epoch 12/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.5407 - mean_absolute_error: 2.9172 - acc: 0.0000e+00 - val_loss: 17.8647 - val_mean_absolute_error: 3.2218 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 13.12279\n",
      "Epoch 13/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.6907 - mean_absolute_error: 2.9081 - acc: 0.0000e+00 - val_loss: 13.9724 - val_mean_absolute_error: 3.3225 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 13.12279\n",
      "Epoch 14/30\n",
      "651/651 [==============================] - 24s 36ms/step - loss: 12.4288 - mean_absolute_error: 2.9130 - acc: 0.0000e+00 - val_loss: 16.3036 - val_mean_absolute_error: 3.1000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 13.12279\n",
      "Epoch 15/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.6513 - mean_absolute_error: 2.9018 - acc: 0.0000e+00 - val_loss: 16.7116 - val_mean_absolute_error: 3.6503 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 13.12279\n",
      "Epoch 16/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.5314 - mean_absolute_error: 2.9043 - acc: 0.0000e+00 - val_loss: 44.2567 - val_mean_absolute_error: 5.7671 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 13.12279\n",
      "Epoch 17/30\n",
      "651/651 [==============================] - 24s 37ms/step - loss: 12.4369 - mean_absolute_error: 2.8819 - acc: 0.0000e+00 - val_loss: 22.1322 - val_mean_absolute_error: 3.5358 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 13.12279\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30 # defines for how many times the training will repeat. 1 epoch is 1 forward pass and 1 backward pass over all the training examples\n",
    "BATCH_SIZE= 20 # the number of training examples in one forward/backward pass (or for 1 epoch)\n",
    "history1= model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          batch_size= BATCH_SIZE, \n",
    "          epochs = NUM_EPOCHS,\n",
    "          callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bJ8tQWMpx_8"
   },
   "source": [
    "# Step 3: Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r6PIHp4p1j_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 4s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.82239742069454, 3.3296790908981158, 0.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pWsjo8fV812"
   },
   "outputs": [],
   "source": [
    "log_dir ='Results00/'\n",
    "from os.path import exists, join\n",
    "with open(join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeszU1NTp1-c"
   },
   "source": [
    "# Step 4: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Results00/SavedModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qFMHFfep4xo"
   },
   "outputs": [],
   "source": [
    "model.predict_on_batch(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Load Pre-Trained Model, Compile, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = load_model('Results00/SavedModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 48, 60, 46, 64)    5248      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 48, 60, 46, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 48, 60, 46, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 24, 30, 23, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 30, 23, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 24, 30, 23, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 24, 30, 23, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 15, 11, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 15, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 12, 15, 11, 16)    13840     \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 12, 15, 11, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 7, 5, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 7, 5, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 6, 7, 5, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 6, 7, 5, 8)        1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 3, 2, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 2, 8)        32        \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 1, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 1024)              9216      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 346,257\n",
      "Trainable params: 346,017\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrain_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CMI_T1w_age_predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
